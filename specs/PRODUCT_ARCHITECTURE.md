# Spark Assistant - Product Architecture

**Status:** Specification Phase  
**Date:** 2024

---

## System Overview

Spark consists of TWO products:

### 1. Obsidian Plugin (UI Layer)
A single plugin with two features:
- **Slash Commands**: Surface custom commands and agents
- **Chat Widget**: Floating chat interface (Cmd+K)

### 2. Spark Daemon (Intelligence Layer)
A standalone Node.js process that:
- Watches vault for changes
- Parses Spark syntax in markdown files
- Executes commands and workflows
- Writes results back to files

---

## Product 1: Obsidian Plugin

### Purpose
Provide UI for interacting with Spark. **Zero business logic.**

### Feature 1: Slash Commands

**What it does:**
- Registers `/` as trigger in Obsidian
- Shows fuzzy-searchable command palette
- Lists all commands from `.spark/commands/`
- Lists all agents from `.spark/agents/`
- Writes selected command/agent to current file

**Example:**

User types: `/`

Plugin shows:
```
┌─────────────────────────────────┐
│ Spark Commands                  │
├─────────────────────────────────┤
│ /summarize                      │
│ /extract-tasks                  │
│ /email-draft                    │
│ /create-report                  │
│                                 │
│ Agents                          │
│ @betty (Accounting)             │
│ @legal (Legal Advisor)          │
│ @analyst (Data Analyst)         │
└─────────────────────────────────┘
```

User selects `/summarize`

Plugin writes to file:
```markdown
/summarize
```

**That's it. Plugin's job is done.**

### Feature 2: Chat Widget

**What it does:**
- Opens floating chat window on `Cmd+K`
- User types messages
- Plugin writes to conversation file
- Daemon processes and responds
- Plugin displays responses

**Example:**

User presses: `Cmd+K`

Plugin opens:
```
┌─────────────────────────────────────┐
│ Spark Assistant              [x]    │
├─────────────────────────────────────┤
│                                     │
│ You: @betty what's our burn rate?  │
│                                     │
│ Betty: Analyzing @finance/2024/... │
│ Your current burn rate is $47K/month│
│                                     │
│ You: ▮                              │
└─────────────────────────────────────┘
```

**Where messages are stored:**

Plugin writes to: `.spark/conversations/2024-01-15-session-abc123.md`

```markdown
---
session_id: abc123
started: 2024-01-15T10:30:00Z
---

**User:** @betty what's our burn rate?

**Betty:** Analyzing @finance/2024/...
Your current burn rate is $47K/month
```

Daemon watches this file, processes new user messages, appends responses.

### Feature 3: Notifications

**What it does:**
- Watches `.spark/notifications.jsonl`
- Shows toast notifications for daemon events
- Updates status bar with current activity

**Example:**

Daemon appends to notifications file:
```json
{"type": "success", "message": "Summary completed", "timestamp": 1234567890}
```

Plugin shows:
```
┌──────────────────────────┐
│ ✓ Summary completed      │
└──────────────────────────┘
```

---

## Product 2: Spark Daemon

### Purpose
All intelligence. Watches files, parses syntax, executes workflows, writes results.

### Core Responsibilities

#### 1. File Watching

Watch all `.md` files in vault:
```typescript
watch([
  'vault/**/*.md',
], {
  ignore: ['.git/**', '.obsidian/**', 'node_modules/**']
})
```

Detect changes with 300ms debounce.

#### 2. Syntax Parsing

Parse markdown for Spark syntax:

**Commands:**
- `/summarize`
- `/extract-tasks`
- `/email-draft`

**Mentions:**
- `@betty` (agent)
- `@finance/Q4/` (folder)
- `@compliance-rules.md` (file)
- `$quickbooks` (service)
- `#urgent` (tag)

**Complex chains:**
```
@betty review @finance/Q4/ comparing with $quickbooks and /create-report
```

#### 3. Context Loading

For each mention, load appropriate context:

| Mention | Action |
|---------|--------|
| `@betty` | Load agent config from `.spark/agents/betty.md` |
| `@finance/Q4/` | Load all files in that folder |
| `@rules.md` | Load file content |
| `$quickbooks` | Connect to QuickBooks API |
| `#urgent` | Find all files tagged `#urgent` |

#### 4. AI Execution

1. Build prompt from command + context + agent persona
2. Call Claude API
3. Get response
4. Parse response for any file operations

#### 5. Result Writing

**Before:**
```markdown
Some content...

@betty review @finance/Q4/ and /create-report

More content...
```

**After:**
```markdown
Some content...

✅ @betty review @finance/Q4/ and /create-report

**Betty's Analysis:**
I've reviewed all Q4 financial documents. Here's the summary:
- Revenue: $450K
- Expenses: $320K
- Net: $130K

Full report: @reports/q4-analysis.md

More content...
```

#### 6. Status Indicators

Add emoji to show command status:

| Status | Indicator |
|--------|-----------|
| Pending | (no emoji) |
| Processing | `⏳` |
| Completed | `✅` |
| Error | `❌` |
| Warning | `⚠️` |

**Example progression:**

User types:
```markdown
@betty summarize this
```

Daemon detects → adds processing indicator:
```markdown
⏳ @betty summarize this
```

Daemon completes → updates to completed:
```markdown
✅ @betty summarize this

Summary here...
```

#### 7. SOP System

Watch for frontmatter changes that trigger SOPs:

**File:**
```markdown
---
email_status: send_this_out
to: client@example.com
---

Email content here...
```

**Trigger config:** `.spark/triggers/frontmatter.yaml`
```yaml
- field: email_status
  value: send_this_out
  sop: email-automation.md
```

**SOP execution:**
1. Daemon detects `email_status` changed to `send_this_out`
2. Loads `.spark/sops/email-automation.md`
3. Executes SOP (which is an AI prompt with instructions)
4. SOP sends email via `$gmail`
5. SOP updates frontmatter: `email_status: sent`
6. SOP adds `sent_date: 2024-01-15`

#### 8. Notifications

Append to `.spark/notifications.jsonl` for plugin:

```jsonl
{"id": "abc", "type": "success", "message": "Summary completed", "file": "notes.md", "timestamp": 1234567890}
{"id": "def", "type": "error", "message": "Rate limit exceeded", "file": "email.md", "timestamp": 1234567891}
{"id": "ghi", "type": "info", "message": "Processing 15 files...", "progress": 0.45, "timestamp": 1234567892}
```

---

## Communication Flow

### Slash Command Flow

```
┌──────────────────┐
│ User types /sum  │
│ in Obsidian      │
└────────┬─────────┘
         │
         ▼
┌─────────────────────────┐
│ Plugin shows palette    │
│ User selects /summarize │
└────────┬────────────────┘
         │
         ▼
┌────────────────────────┐
│ Plugin writes to file: │
│ /summarize             │
└────────┬───────────────┘
         │
         ▼
┌──────────────────────────┐
│ Daemon detects file save │
└────────┬─────────────────┘
         │
         ▼
┌────────────────────────┐
│ Daemon parses file     │
│ Finds: /summarize      │
└────────┬───────────────┘
         │
         ▼
┌──────────────────────┐
│ Daemon adds: ⏳       │
└────────┬─────────────┘
         │
         ▼
┌────────────────────────┐
│ Daemon loads context   │
│ Calls Claude API       │
│ Gets summary           │
└────────┬───────────────┘
         │
         ▼
┌──────────────────────┐
│ Daemon writes result: │
│ ✅ /summarize         │
│                       │
│ Summary: ...          │
└────────┬──────────────┘
         │
         ▼
┌────────────────────────┐
│ Daemon appends to      │
│ notifications.jsonl    │
└────────┬───────────────┘
         │
         ▼
┌────────────────────────┐
│ Plugin detects notif   │
│ Shows toast: ✓ Done    │
└────────────────────────┘
```

### Chat Widget Flow

```
┌──────────────────────┐
│ User presses Cmd+K   │
└────────┬─────────────┘
         │
         ▼
┌────────────────────────┐
│ Plugin opens chat UI   │
└────────┬───────────────┘
         │
         ▼
┌──────────────────────────┐
│ User types:              │
│ @betty what's burn rate? │
└────────┬─────────────────┘
         │
         ▼
┌──────────────────────────────┐
│ Plugin appends to:           │
│ .spark/conversations/xyz.md  │
│                              │
│ **User:** @betty what's...   │
└────────┬─────────────────────┘
         │
         ▼
┌──────────────────────────┐
│ Daemon detects file save │
└────────┬─────────────────┘
         │
         ▼
┌────────────────────────┐
│ Daemon parses:         │
│ - @betty (load agent)  │
│ - Question             │
└────────┬───────────────┘
         │
         ▼
┌────────────────────────┐
│ Daemon calls Claude    │
│ with betty persona     │
└────────┬───────────────┘
         │
         ▼
┌──────────────────────────┐
│ Daemon appends response: │
│                          │
│ **Betty:** Your burn...  │
└────────┬─────────────────┘
         │
         ▼
┌──────────────────────────┐
│ Plugin detects file      │
│ change, displays new msg │
└──────────────────────────┘
```

### SOP Automation Flow

```
┌──────────────────────────┐
│ User edits frontmatter:  │
│ email_status: send_this  │
└────────┬─────────────────┘
         │
         ▼
┌──────────────────────────┐
│ Daemon detects change    │
└────────┬─────────────────┘
         │
         ▼
┌──────────────────────────┐
│ Daemon checks triggers   │
│ Finds matching SOP       │
└────────┬─────────────────┘
         │
         ▼
┌──────────────────────────┐
│ Daemon loads SOP file    │
│ .spark/sops/email.md     │
└────────┬─────────────────┘
         │
         ▼
┌──────────────────────────┐
│ Daemon executes SOP:     │
│ 1. Format email          │
│ 2. Send via $gmail       │
│ 3. Update frontmatter    │
│ 4. Move to sent/         │
└────────┬─────────────────┘
         │
         ▼
┌──────────────────────────┐
│ Daemon sends notification│
│ "Email sent"             │
└──────────────────────────┘
```

---

## File Structure

```
vault/
├── .spark/
│   ├── commands/              # Slash command definitions
│   │   ├── summarize.md
│   │   ├── extract-tasks.md
│   │   └── email-draft.md
│   │
│   ├── agents/                # AI personas
│   │   ├── betty.md           # Accounting agent
│   │   ├── legal.md           # Legal advisor
│   │   └── analyst.md         # Data analyst
│   │
│   ├── sops/                  # Automated workflows
│   │   ├── email-automation.md
│   │   ├── task-assignment.md
│   │   └── invoice-processing.md
│   │
│   ├── triggers/              # SOP trigger configs
│   │   └── frontmatter.yaml
│   │
│   ├── conversations/         # Chat history
│   │   ├── 2024-01-15-session-abc.md
│   │   └── 2024-01-15-session-def.md
│   │
│   ├── integrations/          # External services
│   │   ├── gmail/
│   │   ├── quickbooks/
│   │   └── stripe/
│   │
│   ├── notifications.jsonl    # Daemon → Plugin messages
│   ├── config.yaml            # Main configuration
│   └── logs/                  # Daemon logs
│       └── daemon.log
│
└── [user's regular vault files]
```

---

## Component Responsibilities

### Plugin Responsibilities
✅ Display slash command palette  
✅ Show chat widget UI  
✅ Write user input to files  
✅ Watch notification file  
✅ Display toasts  
✅ Update status bar  

❌ NO parsing  
❌ NO AI calls  
❌ NO business logic  
❌ NO context loading  
❌ NO file processing  

### Daemon Responsibilities
✅ Watch all .md files  
✅ Parse Spark syntax  
✅ Load contexts (files, folders, agents)  
✅ Call AI APIs  
✅ Execute commands  
✅ Run SOPs  
✅ Write results to files  
✅ Send notifications  
✅ Handle errors and retries  

❌ NO UI  
❌ NO Obsidian API interaction  

---

## Key Design Principles

### 1. File System as API
All communication happens via files. No HTTP, WebSocket, or IPC needed.

### 2. Plugin is Dumb
Plugin is pure UI. All intelligence in daemon.

### 3. Raw User Input
Plugin writes exactly what user types. Daemon does all parsing.

### 4. Visual Feedback
Daemon modifies files to show status (✅, ❌, ⏳).

### 5. Zero Dependencies
Plugin works without daemon (just writes files).  
Daemon works without plugin (processes any .md changes).

### 6. Inspectable
Everything is in markdown files. Users can see, edit, and understand what's happening.

### 7. Version Control Friendly
All Spark syntax is valid markdown. No binary formats.

---

## Implementation Priorities

### Phase 1: Core Loop (Week 1)
- [ ] Basic daemon file watcher
- [ ] Parse simple slash commands (`/summarize`)
- [ ] Execute command → call Claude
- [ ] Write result back to file
- [ ] Basic plugin: slash command palette

**Goal:** User types `/summarize`, daemon processes it, result appears in file.

### Phase 2: Mentions (Week 2)
- [ ] Parse `@file.md` mentions
- [ ] Load file context
- [ ] Parse `@folder/` mentions
- [ ] Parse `@agent` mentions
- [ ] Load agent persona

**Goal:** Complex mentions work: `@betty review @folder/`

### Phase 3: Chat Widget (Week 3)
- [ ] Plugin: chat UI
- [ ] Write to conversation files
- [ ] Daemon: process conversation files
- [ ] Maintain conversation context

**Goal:** Cmd+K opens chat, user can talk to @betty

### Phase 4: SOPs (Week 4)
- [ ] Frontmatter change detection
- [ ] Trigger configuration
- [ ] SOP execution
- [ ] Example: email automation

**Goal:** Change `email_status: send` → email sent automatically

### Phase 5: MCP Integration (Week 5)
- [ ] Detect `$service` mentions in text
- [ ] Call MCP servers via stdio/HTTP
- [ ] Pass context and get results
- [ ] Handle MCP server errors

**Goal:** `$quickbooks` calls existing MCP server

**Assumption:** MCP servers already installed and configured on user's machine

### Phase 6: Polish (Week 6)
- [ ] Error handling
- [ ] Notifications
- [ ] Status indicators
- [ ] Logging
- [ ] Configuration

**Goal:** Production-ready for dogfooding

---

## Success Metrics

### Week 1 Success:
✅ Type `/summarize` → see summary appear in file

### Week 2 Success:
✅ Type `@betty review @folder/` → see analysis appear

### Week 3 Success:
✅ Press Cmd+K, chat with @betty, get responses

### Week 4 Success:
✅ Change frontmatter → automation runs automatically

### Week 5 Success:
✅ `$gmail send email` → real email sent

### Week 6 Success:
✅ System handles errors gracefully  
✅ Can dogfood for real work  
✅ Ready to build business features on top

---

## Next Steps

Now that architecture is clear, we need to spec:

1. **Daemon Mention Parser** - How to parse complex mention chains
2. **Command Definition Format** - What goes in `.spark/commands/*.md`
3. **Agent Configuration Format** - What goes in `.spark/agents/*.md`
4. **SOP Format** - What goes in `.spark/sops/*.md`
5. **MCP Integration** - How to connect external services

**Which should we detail first?**
