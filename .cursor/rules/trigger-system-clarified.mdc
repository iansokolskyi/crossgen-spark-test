---
description: trigger system clarification
alwaysApply: false
---
## What Triggers Are

Triggers are rules that:
1. Watch for specific file changes (frontmatter, file creation, etc.)
2. Contain inline instructions for what to do when the change occurs
3. Are processed by the daemon automatically

**No separate SOP files** - the instructions are part of the trigger definition itself.

---

## Trigger File Format

**Location:** `.spark/triggers/`

### Example: Email Automation

```yaml
# .spark/triggers/email-automation.yaml

triggers:
  - name: send_email_on_status_change
    description: Send email when Kanban card moves to "sent"
    
    # What to watch for
    watch:
      directory: "emails/"           # Only watch this directory
      frontmatter_field: status      # Watch this field
      from_value: draft              # Previous value
      to_value: sent                 # New value (triggers when changed to this)
    
    # What to do (instructions are inline, given to Claude)
    instructions: |
      When a file's status changes from "draft" to "sent":
      
      1. Extract the recipient from the `to:` frontmatter field
      2. Extract the subject from the `subject:` frontmatter field
      3. Use the markdown content as the email body
      4. Send email via $gmail
      5. Update frontmatter with: sent_date: [current timestamp]
      6. Move file to sent/[date]/ folder
      7. Create a follow-up task if deadline is mentioned
    
    priority: 10
```

### Example: Task Assignment

```yaml
# .spark/triggers/task-automation.yaml

triggers:
  - name: assign_task_to_agent
    description: When task assigned to AI agent, process it
    
    watch:
      directory: "tasks/"
      frontmatter_field: assigned_to
      pattern: "@*"                  # Any value starting with @
    
    instructions: |
      When a task is assigned to an AI agent:
      
      1. Extract the agent name from assigned_to field (e.g., @betty)
      2. Load that agent's persona from .spark/agents/[agent].md
      3. Read the task description from the file content
      4. Execute the task using the agent's capabilities
      5. Update frontmatter: status: "in_progress"
      6. Write results back to the file
      7. Update frontmatter: status: "completed", completed_date: [timestamp]
    
    priority: 8
```

### Example: Invoice Processing

```yaml
# .spark/triggers/invoice-automation.yaml

triggers:
  - name: new_invoice_created
    description: Process new invoices automatically
    
    watch:
      directory: "invoices/"
      event: file_created           # Trigger on new file
      file_pattern: "*.md"
    
    instructions: |
      When a new invoice file is created:
      
      1. Extract invoice details from frontmatter (client, amount, date, items)
      2. Validate all required fields are present
      3. Create invoice in $quickbooks
      4. Generate PDF version of invoice
      5. Send invoice to client via $gmail
      6. Update frontmatter: status: "sent", quickbooks_id: [id]
      7. Schedule payment reminder for due date
    
    priority: 10
  
  - name: invoice_overdue
    description: Remind about overdue invoices
    
    watch:
      directory: "invoices/"
      frontmatter_field: status
      value: overdue                # Manually set by user or another system
    
    instructions: |
      When an invoice becomes overdue:
      
      1. Load invoice details
      2. Generate friendly reminder email
      3. Send reminder via $gmail
      4. Update frontmatter: last_reminder: [timestamp]
      5. Schedule next reminder for 7 days later
    
    priority: 5
```

---

## How Triggers Work

### Step 1: Daemon Watches Files

The daemon continuously monitors the vault for changes:
- Frontmatter field changes
- File creation/deletion
- File moves

### Step 2: Match Triggers

When a change occurs, daemon checks all triggers to see if any match:

```typescript
interface TriggerMatch {
  trigger: Trigger;
  file: string;
  change: FileChange;
}

function findMatchingTriggers(change: FileChange): TriggerMatch[] {
  const matches: TriggerMatch[] = [];
  
  for (const trigger of loadedTriggers) {
    if (triggerMatches(trigger, change)) {
      matches.push({
        trigger,
        file: change.file,
        change
      });
    }
  }
  
  // Sort by priority (highest first)
  matches.sort((a, b) => b.trigger.priority - a.trigger.priority);
  
  return matches;
}
```

### Step 3: Execute All Matching Triggers

**If multiple triggers match, execute ALL of them in priority order:**

```typescript
async function processTriggers(matches: TriggerMatch[]) {
  for (const match of matches) {
    try {
      await executeTrigger(match);
    } catch (error) {
      // Log error, continue with next trigger
      await handleTriggerError(error, match);
    }
  }
}
```

**Why execute all?** Allows composition:
- Trigger 1: Send email
- Trigger 2: Log the action
- Trigger 3: Update analytics

All three can run on the same file change.

### Step 4: Execute Trigger Instructions

The trigger instructions are given to Claude as a prompt:

```typescript
async function executeTrigger(match: TriggerMatch) {
  // Build prompt from trigger instructions
  const prompt = buildTriggerPrompt({
    instructions: match.trigger.instructions,
    file: match.file,
    change: match.change
  });
  
  // Load context
  const context = await loadContext({
    currentFile: match.file,
    mentions: parseMentionsInInstructions(match.trigger.instructions)
  });
  
  // Execute with Claude
  const result = await claude.complete(prompt, context);
  
  // Handle result (may include file modifications, API calls, etc.)
  await processResult(result, match.file);
}
```

---

## Trigger Watch Types

### 1. Frontmatter Field Change

```yaml
watch:
  directory: "tasks/"
  frontmatter_field: status
  from_value: todo          # Optional: only trigger when changing FROM this
  to_value: done            # Trigger when changing TO this
```

### 2. Frontmatter Pattern Match

```yaml
watch:
  directory: "emails/"
  frontmatter_field: assigned_to
  pattern: "@*"             # Regex or glob pattern
```

### 3. File Creation

```yaml
watch:
  directory: "invoices/"
  event: file_created
  file_pattern: "*.md"
```

### 4. File Deletion

```yaml
watch:
  directory: "archive/"
  event: file_deleted
```

### 5. File Move

```yaml
watch:
  from_directory: "drafts/"
  to_directory: "published/"
  event: file_moved
```

### 6. Any File Change

```yaml
watch:
  directory: "monitored/"
  event: any_change        # Any modification
```

---

## Example Use Case: Kanban Email Workflow

**Setup:**
1. User has Obsidian Kanban plugin
2. Email drafts are cards on the board
3. Card position is determined by `status` frontmatter field

**Trigger:**

```yaml
# .spark/triggers/kanban-email.yaml

triggers:
  - name: kanban_email_send
    description: Send email when moved to "sent" column
    
    watch:
      directory: "emails/"
      frontmatter_field: status
      to_value: sent
    
    instructions: |
      This file was moved to the "sent" column on the Kanban board.
      
      1. Check frontmatter for:
         - to: recipient email address
         - subject: email subject line
         - cc: (optional) CC recipients
         - bcc: (optional) BCC recipients
      
      2. If any required fields are missing, show error notification
      
      3. Format the markdown content as HTML email
      
      4. Send email via $gmail using the extracted information
      
      5. Update frontmatter:
         - Add: sent_date: [current timestamp]
         - Add: gmail_message_id: [message ID from Gmail]
      
      6. Move file to emails/sent/[year]/[month]/ folder
      
      7. Show success notification: "Email sent to [recipient]"
    
    priority: 10
```

**Workflow:**

1. User writes email in `emails/draft-client-proposal.md`:
   ```markdown
   ---
   to: client@company.com
   subject: Q4 Proposal
   status: draft
   ---
   
   Hi Client,
   
   Here's our proposal for Q4...
   ```

2. User drags card to "sent" column in Kanban board

3. Obsidian updates frontmatter: `status: sent`

4. Daemon detects the change

5. Trigger matches and executes instructions

6. Claude:
   - Reads the frontmatter
   - Formats the content as email
   - Calls $gmail to send
   - Updates the file
   - Moves it to sent folder

7. User sees notification: "✓ Email sent to client@company.com"

**All automatic. Zero clicks beyond moving the card.**

---

## Multiple Triggers Example

**Scenario:** Invoice file created

```yaml
# .spark/triggers/invoice-automation.yaml

triggers:
  # Trigger 1: Process the invoice
  - name: process_invoice
    watch:
      directory: "invoices/"
      event: file_created
    instructions: |
      Create invoice in QuickBooks and send to client
    priority: 10
  
  # Trigger 2: Log the creation
  - name: log_invoice
    watch:
      directory: "invoices/"
      event: file_created
    instructions: |
      Append invoice details to invoices/log.md
    priority: 5
  
  # Trigger 3: Update metrics
  - name: update_metrics
    watch:
      directory: "invoices/"
      event: file_created
    instructions: |
      Update financial dashboard with new invoice amount
    priority: 3
```

When invoice created:
1. Process invoice (priority 10) - sends to QuickBooks, emails client
2. Log invoice (priority 5) - adds entry to log file
3. Update metrics (priority 3) - updates dashboard

**All three execute automatically in order.**

---

## Trigger Configuration

**Main config:** `.spark/config.yaml`

```yaml
triggers:
  enabled: true
  
  # Directories to watch
  watch_directories:
    - "emails/"
    - "tasks/"
    - "invoices/"
    - "clients/"
  
  # How often to check for changes (if not using file system events)
  polling_interval_ms: 1000
  
  # Debounce rapid changes
  debounce_ms: 300
  
  # Execution
  execute_all_matches: true    # Run all matching triggers
  stop_on_error: false         # Continue even if one fails
  
  # Timeout for each trigger execution
  timeout_ms: 60000
```

---

## Comparison: Commands vs Triggers

| Aspect | Commands (`/command`) | Triggers (`watch:`) |
|--------|----------------------|---------------------|
| **Activation** | User types explicitly | Automatic on file change |
| **Context** | Current file + mentions | File that changed |
| **Purpose** | On-demand action | Automated workflow |
| **Example** | `/summarize` | Email on status change |
| **Statefulness** | Stateless | Watches for state changes |

**Both use the same underlying system:**
- Same mention parser
- Same context loading
- Same Claude integration
- Same error handling

The only difference: **how they're triggered**.

---

## Summary

**Key Points:**

1. ✅ Triggers contain instructions inline (not references to separate SOP files)
2. ✅ Multiple triggers can match the same change (all execute in priority order)
3. ✅ Triggers enable true automation (no user action required)
4. ✅ Triggers use the same AI system as commands
5. ✅ Perfect for Kanban workflows, status changes, file creation

**The trigger system transforms Spark from "AI assistant" to "AI automation platform".**

---

## Next Steps

With triggers clarified:
1. Update CONFIGURATION.md to reflect inline instructions
2. Update FILE_FORMATS.md to show trigger format
3. Create implementation plan with trigger system included

Ready to proceed?
